import { ChromaClient } from 'chromadb';
import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters';
import fs from 'fs/promises';
import path from 'path';
import { v4 as uuidv4 } from 'uuid';

const CHROMA_URL = 'http://localhost:8000';
const COLLECTION_NAME = 'docs';
const DOCS_DIR = './docs';

async function ingestDocuments() {
  console.log('🚀 Starting document ingestion...');

  // Initialize ChromaDB client
  const client = new ChromaClient({ path: CHROMA_URL });

  // Get or create collection (will use default embeddings)
  let collection;
  try {
    await client.deleteCollection({ name: COLLECTION_NAME });
    console.log(`🗑️  Deleted existing collection: ${COLLECTION_NAME}`);
  } catch (error) {
    // Collection doesn't exist, that's fine
  }
  
  collection = await client.createCollection({ name: COLLECTION_NAME });
  console.log(`📦 Created collection with default embeddings: ${COLLECTION_NAME}`);

  // todo introduce chunk splitting to injest.ts
  // Text splitter
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  });

  // Read all markdown files
  const files = await fs.readdir(DOCS_DIR);
  const mdFiles = files.filter(f => f.endsWith('.md'));

  console.log(`📄 Found ${mdFiles.length} markdown files`);

  for (const file of mdFiles) {
    const filePath = path.join(DOCS_DIR, file);
    const content = await fs.readFile(filePath, 'utf-8');
    
    // Split into chunks
    const chunks = await splitter.splitText(content);
    console.log(`  ├─ ${file}: ${chunks.length} chunks`);

    // Add to ChromaDB (embeddings generated automatically)
    const ids = chunks.map(() => uuidv4());
    const metadatas = chunks.map((_, i) => ({
      source: file,
      chunk: i,
    }));

    await collection.add({
      ids,
      documents: chunks,
      metadatas,
    });
  }

  console.log('✅ Ingestion complete!');
}

ingestDocuments().catch(console.error);